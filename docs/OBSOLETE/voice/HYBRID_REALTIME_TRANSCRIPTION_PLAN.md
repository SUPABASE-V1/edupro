# Hybrid Real-Time Transcription Architecture Plan

**Date:** 2025-10-14  
**Status:** üìã PLANNING  
**Priority:** üî¥ HIGH  
**Target:** Real-time user feedback using batch method + ASR

---

## üéØ Executive Summary

**Problem:** Current batch transcription is too slow (5-10 seconds), creating poor UX for Dash voice interactions.

**Solution:** Hybrid 3-tier approach combining:
1. **Tier 1**: On-device ASR (instant feedback, <500ms)
2. **Tier 2**: Chunked batch transcription (progressive updates, 1-2s cadence)
3. **Tier 3**: Final pass with Whisper (accuracy, 3-5s)

**Key Principle:** Keep using batch method (OpenAI Whisper) but make it feel real-time through chunking and on-device ASR masking.

---

## üèóÔ∏è Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         USER INTERFACE                          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  [üé§ Recording] ‚Üí [üìù Instant Text] ‚Üí [üîÑ Progressive] ‚Üí [‚úì Final]‚îÇ
‚îÇ   Device ASR      Device interim      Chunked batch    Whisper  ‚îÇ
‚îÇ   <500ms          ~200-800ms          ~1-2s cadence    ~3-5s    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   HYBRID TRANSCRIPTION MANAGER                  ‚îÇ
‚îÇ                  (lib/speech/hybrid-transcription.ts)           ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Orchestrates 3 tiers:                                         ‚îÇ
‚îÇ  ‚Ä¢ Tier 1: On-Device ASR (instant UX)                          ‚îÇ
‚îÇ  ‚Ä¢ Tier 2: Chunked Batch (progressive accuracy)                ‚îÇ
‚îÇ  ‚Ä¢ Tier 3: Final Pass (full accuracy)                          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Merging Strategy:                                             ‚îÇ
‚îÇ  ‚Ä¢ Show device interim for current segment                     ‚îÇ
‚îÇ  ‚Ä¢ Replace with chunk results as they arrive                   ‚îÇ
‚îÇ  ‚Ä¢ Replace entire transcript with final on stop                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñº                    ‚ñº                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   TIER 1       ‚îÇ  ‚îÇ   TIER 2       ‚îÇ  ‚îÇ   TIER 3       ‚îÇ
‚îÇ  On-Device ASR ‚îÇ  ‚îÇ Chunked Batch  ‚îÇ  ‚îÇ  Final Pass    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Web:           ‚îÇ  ‚îÇ Web:           ‚îÇ  ‚îÇ All Platforms: ‚îÇ
‚îÇ - Web Speech   ‚îÇ  ‚îÇ - MediaRecorder‚îÇ  ‚îÇ - Full audio   ‚îÇ
‚îÇ   API          ‚îÇ  ‚îÇ - 1s timeslice ‚îÇ  ‚îÇ - Upload once  ‚îÇ
‚îÇ - interimRes.  ‚îÇ  ‚îÇ - POST chunks  ‚îÇ  ‚îÇ - Whisper API  ‚îÇ
‚îÇ                ‚îÇ  ‚îÇ                ‚îÇ  ‚îÇ - 3-5s SLA     ‚îÇ
‚îÇ Mobile:        ‚îÇ  ‚îÇ Mobile:        ‚îÇ  ‚îÇ - Replace all  ‚îÇ
‚îÇ - iOS Speech   ‚îÇ  ‚îÇ - expo-av      ‚îÇ  ‚îÇ   text         ‚îÇ
‚îÇ - Android ASR  ‚îÇ  ‚îÇ - 2s chunks    ‚îÇ  ‚îÇ - Deepgram     ‚îÇ
‚îÇ - react-native ‚îÇ  ‚îÇ - stop/start   ‚îÇ  ‚îÇ   fallback     ‚îÇ
‚îÇ   -voice       ‚îÇ  ‚îÇ - upload each  ‚îÇ  ‚îÇ                ‚îÇ
‚îÇ                ‚îÇ  ‚îÇ                ‚îÇ  ‚îÇ                ‚îÇ
‚îÇ Latency:       ‚îÇ  ‚îÇ Latency:       ‚îÇ  ‚îÇ Latency:       ‚îÇ
‚îÇ <500ms         ‚îÇ  ‚îÇ 1-2s per chunk ‚îÇ  ‚îÇ 3-5s total     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  AI-PROXY-ASR  ‚îÇ
                    ‚îÇ  Edge Functions‚îÇ
                    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                    ‚îÇ /transcribe-   ‚îÇ
                    ‚îÇ  chunk         ‚îÇ
                    ‚îÇ /transcribe-   ‚îÇ
                    ‚îÇ  final         ‚îÇ
                    ‚îÇ /transcribe-   ‚îÇ
                    ‚îÇ  health        ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  OpenAI Whisper‚îÇ
                    ‚îÇ  (Primary)     ‚îÇ
                    ‚îÇ                ‚îÇ
                    ‚îÇ  Deepgram      ‚îÇ
                    ‚îÇ  (Fallback)    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Performance Targets

### Current State (Batch Only)
```
User stops speaking
  ‚Üì
Recording stops: ~100ms
  ‚Üì
Upload to storage: 1-2s
  ‚Üì
Edge function downloads: 200-500ms
  ‚Üì
Whisper transcription: 3-5s
  ‚Üì
TOTAL: 5-10 seconds ‚ùå
```

### Target State (Hybrid)
```
User starts speaking
  ‚Üì
On-device ASR starts: <500ms ‚úì (INSTANT FEEDBACK)
  ‚Üì
First chunk transcribed: ~1.5s ‚úì (PROGRESSIVE UPDATE)
  ‚Üì
Subsequent chunks: ~1-2s each ‚úì (REAL-TIME FEEL)
  ‚Üì
User stops speaking
  ‚Üì
Final pass completes: 3-5s ‚úì (ACCURACY)
  ‚Üì
PERCEIVED LATENCY: <500ms to first text ‚úÖ
ACTUAL ACCURACY: Same or better than current ‚úÖ
```

### SLA Targets

| Metric | Target | Current |
|--------|--------|---------|
| **First Feedback** | <500ms (device) | 5-10s |
| **First Chunk** | <1.5s | N/A |
| **Chunk Cadence** | 1-2s | N/A |
| **Final Accuracy** | ‚â• current | baseline |
| **Error Rate** | <5% | unknown |
| **Perceived Speed** | 10x faster | baseline |

---

## üîß Implementation Phases

### Phase 1: Foundation (Week 1)
**Goal:** Quick wins + infrastructure

1. ‚úÖ **Audio Compression** (15 min)
   - Update `lib/voice-pipeline.ts` recording config
   - 16kHz, mono, 32kbps ‚Üí 84% size reduction
   - Expected: 80-120 KB per 30s chunk

2. ‚úÖ **Backend Endpoints** (2-3 hours)
   - Create `supabase/functions/ai-proxy-asr/transcribe-chunk/`
   - Create `supabase/functions/ai-proxy-asr/transcribe-final/`
   - Create `supabase/functions/ai-proxy-asr/transcribe-health/`
   - JWT auth, rate limiting, logging

3. ‚úÖ **On-Device ASR Wrappers** (2-3 hours)
   - `lib/speech/web-asr.ts` (Web Speech API)
   - `lib/speech/native-asr.ts` (iOS/Android)
   - `lib/speech/asr-manager.ts` (unified interface)

4. ‚úÖ **Web Chunked Streaming** (3-4 hours)
   - Update `lib/voice-pipeline.ts`
   - MediaRecorder with 1s timeslice
   - POST chunks to edge function
   - Maintain chunk map and stitch results

**Deliverable:** Web users see instant device feedback + progressive chunks

### Phase 2: Mobile Optimization (Week 2)
**Goal:** Mobile-first improvements

1. ‚úÖ **Mobile Chunking** (2-3 hours)
   - Implement stop/start chunking with expo-av
   - 2s chunks to reduce gaps
   - Double-buffering pattern

2. ‚úÖ **Hybrid Manager** (3-4 hours)
   - Create `lib/speech/hybrid-transcription.ts`
   - Orchestrate 3 tiers
   - Smart merging logic
   - Handle dropped chunks

3. ‚úÖ **UI/UX Integration** (2-3 hours)
   - Update `components/ai/VoiceRecorderSheet.tsx`
   - Update `components/ai/DashAssistant.tsx`
   - Progress states and badges
   - Accessibility support

**Deliverable:** Mobile users see device ASR + chunked batch + final

### Phase 3: Advanced Streaming (Week 3 - Optional)
**Goal:** Sub-second updates for power users

1. ‚ö†Ô∏è **WebSocket Pseudo-Stream** (4-6 hours)
   - Implement `lib/speech/ws-streamer.ts`
   - Edge function WebSocket endpoint
   - 200-300ms frames ‚Üí 1s micro-batches
   - SSE or WS for partials

2. ‚ö†Ô∏è **Native Streaming Module** (6-8 hours)
   - Add `react-native-live-audio-stream`
   - Replace stop/start with PCM frames
   - 200-500ms frame rate
   - Requires EAS dev client

**Deliverable:** 300-600ms latency for web power users

---

## üìÅ File Structure

```
edudashpro/
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îú‚îÄ‚îÄ speech/                          # NEW DIRECTORY
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web-asr.ts                  # Web Speech API wrapper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ native-asr.ts               # iOS/Android ASR
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ asr-manager.ts              # Unified interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hybrid-transcription.ts     # Orchestrator
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ws-streamer.ts              # Optional WebSocket client
‚îÇ   ‚îî‚îÄ‚îÄ voice-pipeline.ts               # UPDATED: chunking logic
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ DashAIAssistant.ts              # UPDATED: use HybridManager
‚îú‚îÄ‚îÄ components/ai/
‚îÇ   ‚îú‚îÄ‚îÄ VoiceRecorderSheet.tsx          # UPDATED: progressive UI
‚îÇ   ‚îî‚îÄ‚îÄ DashAssistant.tsx               # UPDATED: state badges
‚îú‚îÄ‚îÄ supabase/functions/
‚îÇ   ‚îî‚îÄ‚îÄ ai-proxy-asr/                   # NEW EDGE FUNCTIONS
‚îÇ       ‚îú‚îÄ‚îÄ transcribe-chunk/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ index.ts                # Chunk endpoint
‚îÇ       ‚îú‚îÄ‚îÄ transcribe-final/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ index.ts                # Final endpoint
‚îÇ       ‚îî‚îÄ‚îÄ transcribe-health/
‚îÇ           ‚îî‚îÄ‚îÄ index.ts                # Health check
‚îî‚îÄ‚îÄ docs/voice/
    ‚îî‚îÄ‚îÄ HYBRID_REALTIME_TRANSCRIPTION_PLAN.md  # This file
```

---

## üîê Security & Compliance

### Authentication
- All `ai-proxy-asr` endpoints require Supabase JWT
- Verify `preschool_id` context for multi-tenant isolation
- Service role key only server-side (WARP rule compliance)

### Rate Limiting
- Max 60 chunks per session
- 1 request/sec per session baseline
- Burst up to 3 requests/sec
- JWT-based user identification

### Data Handling
- **DO NOT** store chunk audio files
- Store only final transcript in database
- Log usage metrics in `ai_usage_logs`:
  - `preschool_id`, `user_id`
  - `feature: "asr"`
  - `tier: "chunk" | "final" | "device"`
  - `tokens`, `latency_ms`

### PII Protection
- No audio stored beyond transcription window
- Final transcript only persisted
- No cross-tenant data leakage

### Cost Controls
- If audio duration > 90s, increase chunk size to 2s
- Adaptive throttling based on API quotas
- Timeouts: 10s for chunks, 60s for final

---

## üß™ Testing Strategy

### Test Matrix

| Test | Description | Platform | Expected |
|------|-------------|----------|----------|
| **T1** | Normal flow | All | Device <500ms, chunks ~1.5s, final 3-5s |
| **T2** | Offline mode | All | Device only, banner shown |
| **T3** | Network jitter | All | Drop 10-20% chunks, recover in final |
| **T4** | Long recording (60s) | All | 60 chunks, coherent stitching |
| **T5** | Provider failure | All | Fallback to Deepgram, badge shown |
| **T6** | WebSocket stream | Web | 300-600ms partials |
| **T7** | Low-end Android | Mobile | CPU/memory acceptable |
| **T8** | Permissions | All | Graceful degradation |

### Performance Benchmarks

```typescript
// Track metrics
analytics.track('hybrid_transcription_performance', {
  device_asr_latency_ms: 450,
  first_chunk_latency_ms: 1300,
  avg_chunk_latency_ms: 1100,
  final_transcription_latency_ms: 4200,
  total_audio_duration_ms: 30000,
  chunk_count: 30,
  chunk_drop_rate: 0.03,
  network_type: '4g',
  platform: 'web'
});
```

### Alerts
- Alert if first_feedback > 800ms (web) or > 1200ms (mobile)
- Alert if error_rate > 5%
- Alert if final_latency > 8s

---

## üí° Key Design Decisions

### Why Batch Method?
- **Cost:** Whisper batch is significantly cheaper than Realtime API
- **Accuracy:** Whisper batch has better accuracy for SA languages
- **Simplicity:** Fewer moving parts than true WebRTC streaming
- **Compliance:** Easier to log/audit batch calls vs streaming

### Why 3 Tiers?
- **Tier 1 (Device):** Instant UX, masks network latency
- **Tier 2 (Chunks):** Progressive accuracy, feels real-time
- **Tier 3 (Final):** Full accuracy, clean punctuation

### Why 1s Chunks?
- Balance between API QPS and perceived latency
- 2s chunks = more accurate but slower feel
- 500ms chunks = too many API calls, higher cost
- 1s is the sweet spot

### Fallback Strategy
1. Try on-device ASR (if available)
2. Try chunked batch (if online)
3. Try final pass with Whisper
4. Fallback to Deepgram
5. If all fail, keep stitched chunks

---

## üìà Expected Improvements

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| First Feedback | 5-10s | <500ms | **90-95%** ‚úÖ |
| User Perception | "Slow" | "Instant" | **Subjective Win** ‚úÖ |
| Accuracy | Baseline | Same or better | **No Regression** ‚úÖ |
| Cost per minute | $0.006 | $0.006-0.009 | **Minimal increase** ‚úÖ |
| Network usage | 500 KB | 420 KB | **16% reduction** ‚úÖ |
| Error recovery | None | Graceful | **Better UX** ‚úÖ |

---

## üöÄ Rollout Plan

### Week 1: Foundation
- [ ] Audio compression (all platforms)
- [ ] Backend edge functions
- [ ] On-device ASR wrappers
- [ ] Web chunked streaming
- [ ] Basic UI states
- **Deploy to:** Internal testing (dev environment)

### Week 2: Mobile + Polish
- [ ] Mobile chunking
- [ ] Hybrid transcription manager
- [ ] UI/UX polish
- [ ] Performance monitoring
- [ ] Security hardening
- **Deploy to:** Beta testers (10% rollout)

### Week 3: Advanced (Optional)
- [ ] WebSocket pseudo-stream (web)
- [ ] Native streaming module (mobile)
- [ ] Fine-tuning and optimization
- **Deploy to:** Power users (50% rollout)

### Week 4: Full Rollout
- [ ] Monitor metrics and alerts
- [ ] Fix any critical issues
- [ ] Documentation updates
- **Deploy to:** All users (100% rollout)

### Rollback Plan
- Feature flags allow instant rollback to batch-only
- Keep old transcription path as fallback
- SLO monitoring triggers automatic rollback if error rate > 5%

---

## üéì User Experience Flow

### Current Experience
```
User: [Speaks for 30s]
      [Releases button]
      [Waits... 5-10 seconds... üïê]
      [Finally sees transcript]
      
Feedback: "Is it working? Did it hear me?"
```

### New Hybrid Experience
```
User: [Speaks for 30s]
      [Sees text appearing instantly as they speak] ‚ú®
      [Releases button]
      [Text refines in 1-2 seconds]
      [Final polished version appears in 3-5s] ‚úì
      
Feedback: "Wow, it's so fast! It understands me!"
```

---

## üîß Configuration & Feature Flags

### Environment Variables (.env)

```bash
# Feature Flags
EXPO_PUBLIC_ENABLE_HYBRID_TRANSCRIPTION=true
EXPO_PUBLIC_ENABLE_ON_DEVICE_ASR=true
EXPO_PUBLIC_ENABLE_CHUNKED_TRANSCRIPTION=true
EXPO_PUBLIC_ENABLE_WEBRTC_STREAMING=false
EXPO_PUBLIC_CHUNK_DURATION_MS=1000

# Backend (Edge Function Secrets)
TRANSCRIPTION_PROVIDER=openai
OPENAI_API_KEY=sk-...
OPENAI_TRANSCRIPTION_MODEL=whisper-1
DEEPGRAM_API_KEY=...  # Optional fallback

# Tuning
ASR_CHUNK_TIMEOUT_MS=10000
ASR_FINAL_TIMEOUT_MS=60000
ASR_MAX_CHUNKS_PER_SESSION=60
ASR_MAX_CHUNK_SIZE_MB=2
```

### Runtime Feature Toggles

```typescript
// Via PostHog or custom feature flag service
const config = {
  hybridTranscription: {
    enabled: true,
    deviceASR: true,
    chunkedBatch: true,
    webrtcStreaming: false,
    chunkDurationMs: 1000
  }
};
```

---

## üìö Related Documentation

- [VOICE_TRANSCRIPTION_ENHANCEMENTS.md](../VOICE_TRANSCRIPTION_ENHANCEMENTS.md) - Previous batch improvements
- [TRANSCRIPTION_SPEED_OPTIMIZATION.md](../../docs/performance/TRANSCRIPTION_SPEED_OPTIMIZATION.md) - Speed analysis
- [STREAMING_TRANSCRIPTION_MIGRATION_TODO.md](../STREAMING_TRANSCRIPTION_MIGRATION_TODO.md) - WebRTC migration notes
- [CLIENT_INTEGRATION.md](./CLIENT_INTEGRATION.md) - Voice API usage guide

---

## ‚úÖ Success Criteria

### Technical
- [x] First feedback latency < 500ms (device ASR)
- [ ] First chunk latency < 1.5s
- [ ] Chunk cadence 1-2s
- [ ] Final accuracy ‚â• current baseline
- [ ] Error rate < 5%
- [ ] Works on low-end Android

### User Experience
- [ ] Users perceive 10x speed improvement
- [ ] No regression in transcription quality
- [ ] Graceful offline degradation
- [ ] Clear progress indicators

### Business
- [ ] Cost increase < 50% (chunking overhead)
- [ ] Network usage reduced by audio compression
- [ ] Rollout without incidents
- [ ] Positive user feedback

---

## üêõ Known Limitations & Future Work

### Current Limitations
1. **English Only:** Device ASR and initial chunking English-only (no i18n yet)
2. **Web First:** Mobile streaming is stop/start chunks (gaps possible)
3. **No Offline Queue:** Chunks lost if network drops (final pass recovers)
4. **Punctuation:** Chunks have minimal punctuation (final pass fixes)

### Future Enhancements
1. **Multi-Language ASR:** Support Afrikaans, Zulu, Xhosa on-device models
2. **Native Streaming:** Replace stop/start with continuous PCM frames on mobile
3. **WebRTC True Streaming:** Sub-second updates via WebRTC data channels
4. **Offline Queue:** Cache chunks when offline, sync when online
5. **Speaker Diarization:** Multi-speaker detection for classroom recordings
6. **Custom Vocabulary:** Domain-specific terms (education, SA context)

---

## üôè Acknowledgments

This design synthesizes:
- Existing batch transcription infrastructure (`transcribe-audio` Edge Function)
- WebRTC/streaming research (`STREAMING_TRANSCRIPTION_MIGRATION_TODO.md`)
- Performance optimization insights (`TRANSCRIPTION_SPEED_OPTIMIZATION.md`)
- WARP.md governance rules (AI calls via ai-proxy, server-side secrets)
- Real-world mobile constraints (low-end Android, unreliable networks)

**Design Philosophy:** Maximize perceived speed without sacrificing accuracy or cost-effectiveness, using battle-tested batch APIs as the foundation.

---

**Status:** ‚úÖ Ready for Implementation  
**Next Step:** Begin Phase 1 - Foundation (audio compression + backend endpoints)  
**Owner:** Development Team  
**Timeline:** 3-4 weeks for full rollout

*This document will be updated with implementation progress and benchmark results.*
