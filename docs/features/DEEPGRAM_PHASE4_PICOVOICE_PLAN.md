# Phase 4: Picovoice + Deepgram - Native Audio Solution ğŸ¯

**Your Excellent Idea**: Use the already-installed `@picovoice/react-native-voice-processor` to get raw audio frames and send them to Deepgram!

## Why This Is Perfect âœ…

**Current Situation**:
- âœ… `@picovoice/react-native-voice-processor@1.2.3` - Already installed!
- âœ… Gives us raw audio frames in real-time
- âœ… Works on iOS and Android
- âœ… Designed exactly for this use case!

**What It Does**:
```
Device Microphone 
  â†’ Picovoice Voice Processor 
    â†’ Raw audio frames (Int16Array)
      â†’ Send to Deepgram WebSocket
        â†’ Transcription!
```

## Cost Comparison ğŸ’°

**Phase 3 (Current - OpenAI)**:
- Native: $18/hour ğŸ’¸

**Phase 4 (Picovoice + Deepgram)**:
- Native: **$0.50/hour** âœ…
- Web: $0.50/hour âœ…
- **Same cost everywhere!**

**Savings**: 97% cost reduction! ($18 â†’ $0.50)

## Implementation Plan ğŸ”§

### Step 1: Initialize Picovoice Voice Processor

```typescript
import { VoiceProcessor } from '@picovoice/react-native-voice-processor';

// Start recording
VoiceProcessor.start(
  512,  // Frame length (samples)
  16000 // Sample rate (16kHz for Deepgram)
);

// Add listener for audio frames
const subscription = VoiceProcessor.addFrameListener((frame) => {
  // frame is Int16Array of raw PCM audio
  // Send to Deepgram WebSocket!
  sendAudioToDeepgram(frame.buffer);
});
```

### Step 2: Send Audio to Deepgram

```typescript
// Convert Int16Array to ArrayBuffer
const audioData = frame.buffer; // Raw PCM 16-bit

// Send directly to Deepgram WebSocket
if (deepgramWs && deepgramWs.readyState === WebSocket.OPEN) {
  deepgramWs.send(audioData);
}
```

### Step 3: Update claudeProvider.ts

Replace the MediaRecorder check with Picovoice:

```typescript
} else {
  // Native mobile - use Picovoice Voice Processor
  console.log('[claudeProvider] ğŸ¤ Starting Picovoice voice processor...');
  
  const { VoiceProcessor } = await import('@picovoice/react-native-voice-processor');
  
  // Start capturing audio at 16kHz (Deepgram requirement)
  await VoiceProcessor.start(512, 16000);
  
  // Listen for audio frames
  const frameListener = VoiceProcessor.addFrameListener((frame) => {
    // Send raw PCM to Deepgram
    if (deepgramWs && deepgramWs.readyState === WebSocket.OPEN) {
      deepgramWs.send(frame.buffer);
    }
  });
  
  // Store for cleanup
  audioStreamProcessor = {
    stop: async () => {
      await VoiceProcessor.stop();
      frameListener.remove();
    }
  };
}
```

## Advantages âœ…

1. **Already Installed** - No new dependencies!
2. **Cheap** - $0.50/hour (same as web)
3. **Real-time** - Streams audio continuously
4. **Works Everywhere** - iOS, Android, proven
5. **Raw PCM** - Exactly what Deepgram expects
6. **Claude AI** - Keep using Claude (not OpenAI)

## Potential Issues & Solutions ğŸ”§

### Issue 1: Frame Format
**Problem**: Picovoice gives Int16Array, Deepgram expects certain format  
**Solution**: Convert if needed (likely already compatible)

### Issue 2: Sample Rate
**Problem**: Picovoice might not support 16kHz  
**Solution**: Use 16kHz if available, or resample client-side

### Issue 3: Permissions
**Problem**: Need microphone permissions  
**Solution**: VoiceProcessor handles this (same as OpenAI)

## Testing Plan ğŸ§ª

### Step 1: Basic Test
```typescript
// Test if Picovoice can capture audio
VoiceProcessor.start(512, 16000);
console.log('Picovoice started');

const sub = VoiceProcessor.addFrameListener((frame) => {
  console.log('Got frame:', frame.length, 'samples');
});

// After 5 seconds
setTimeout(async () => {
  await VoiceProcessor.stop();
  sub.remove();
}, 5000);
```

**Expected**: Should log frame data every ~32ms (512 samples @ 16kHz)

### Step 2: Deepgram Integration
```typescript
// Connect to Deepgram
const deepgramWs = new WebSocket('wss://api.deepgram.com/v1/listen?...');

// Send audio frames
VoiceProcessor.addFrameListener((frame) => {
  if (deepgramWs.readyState === WebSocket.OPEN) {
    deepgramWs.send(frame.buffer);
  }
});
```

**Expected**: Deepgram should return transcription results

### Step 3: Full Integration
Test complete flow:
1. User clicks orb
2. Picovoice starts capturing
3. Audio sent to Deepgram
4. Transcription appears
5. Sent to Claude
6. Response via TTS

## Implementation Time â±ï¸

**Estimated**: 15-20 minutes
- 5 min: Add Picovoice initialization
- 5 min: Hook up to Deepgram WebSocket
- 5 min: Test and debug
- 5 min: Cleanup and polish

## Next Steps ğŸš€

Would you like me to:
1. **âœ… Implement this now** (recommended!)
   - Modify claudeProvider.ts
   - Add Picovoice integration
   - Test on your device

2. **Test Picovoice first**
   - Create standalone test
   - Verify audio capture works
   - Then integrate

3. **Check alternatives**
   - Look at other audio libraries
   - Compare performance
   - Make informed decision

## Expected Result ğŸ‰

**After implementation**:
- âœ… Orb works on native
- âœ… Uses Deepgram ($0.50/hour)
- âœ… Uses Claude for AI
- âœ… Real-time streaming
- âœ… 97% cost savings vs OpenAI
- âœ… Same experience as web

**Your original vision achieved!** ğŸ¯
- Claude + Deepgram on ALL platforms
- Cheap, fast, reliable
- No expensive OpenAI fallback needed

---

**Ready to implement?** Let me know and I'll modify the code!
